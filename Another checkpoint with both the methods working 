{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CristianMorasso/statistical_project/blob/master/Another%20checkpoint%20with%20both%20the%20methods%20working%20\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFS000cMNXMb"
      },
      "source": [
        "# Statistical Learning Project: ALFA Dataset Anaysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYUOovxy7XZ8",
        "outputId": "afe788d0-2966-4840-aead-41b91825ee0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: icecream in /usr/local/lib/python3.10/dist-packages (2.1.3)\n",
            "Requirement already satisfied: sktime in /usr/local/lib/python3.10/dist-packages (0.30.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.10/dist-packages (0.20.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: colorama>=0.3.9 in /usr/local/lib/python3.10/dist-packages (from icecream) (0.4.6)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.16.1)\n",
            "Requirement already satisfied: executing>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.0.1)\n",
            "Requirement already satisfied: asttokens>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from icecream) (2.4.1)\n",
            "Requirement already satisfied: joblib<1.5,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.4.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sktime) (24.0)\n",
            "Requirement already satisfied: pandas<2.3.0,>=1.1 in /usr/local/lib/python3.10/dist-packages (from sktime) (2.0.3)\n",
            "Requirement already satisfied: scikit-base<0.9.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from sktime) (0.8.0)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from sktime) (1.11.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from asttokens>=2.0.1->icecream) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=1.1->sktime) (2024.1)\n",
            "fatal: destination path 'statistical_project' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset from our git repository hosted on Github\n",
        "!pip install icecream sktime scikit-learn polars numpy\n",
        "!rm -rf statiscal_project\n",
        "!git clone https://github.com/CristianMorasso/statistical_project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCaKGDiag_ya",
        "outputId": "aefa576b-6542-4690-ce3f-f9b3488700c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "Error for no_failure\n",
            "README.md is not a dir or not useful!\n",
            "__init__.py is not a dir or not useful!\n",
            "features is not a dir or not useful!\n",
            "\n",
            "Number of Time Series: 45\n"
          ]
        }
      ],
      "source": [
        "# Read the data from the csv files\n",
        "import numpy as np\n",
        "import pandas  as pd\n",
        "import os\n",
        "from random import shuffle\n",
        "\n",
        "dataset_dir = \"statistical_project/data\"\n",
        "dfs = [] # dataframe list\n",
        "\n",
        "classToString= {0:\"no_failure\", 1:\"elevator\", 2:\"engine\", 3:\"rudder\",4:\"ailerons\"}\n",
        "\n",
        "stringToClass = {}\n",
        "for key, value in classToString.items():\n",
        "  stringToClass[value] = key\n",
        "\n",
        "series_counter = 0\n",
        "\n",
        "for _, cl  in enumerate(os.listdir(dataset_dir)):\n",
        "  path1 = os.path.join(dataset_dir, cl)\n",
        "\n",
        "  # Get rid of files or bad dirs\n",
        "  if not os.path.isdir(path1) or cl == \"features\":\n",
        "    print(f\"{cl} is not a dir or not useful!\")\n",
        "    continue\n",
        "\n",
        "  for f in  os.listdir(path1):\n",
        "    pathf = os.path.join(path1, f)\n",
        "    df = pd.read_csv(pathf)\n",
        "\n",
        "    # Fix the label field\n",
        "    try:\n",
        "      df[\"field.data\"] = df[\"field.data\"].apply(func=lambda x: stringToClass[cl] if int(x)>0 else 0)\n",
        "      df = df.rename(columns={\"field.data\": \"Y\"})\n",
        "    except:\n",
        "      print(f\"Error for {cl}\")\n",
        "      df[\"Y\"]  = pd.Series([ 0 for _ in range(df.shape[0])])\n",
        "\n",
        "    # Transforming to a pd.multi-indexed-DataFrame\n",
        "    #\n",
        "    # Add the colums for multi-indexing\n",
        "    # df.insert(0, \"flight\", [ series_counter for _ in range(len(df))], True)\n",
        "    # df.insert(1, \"step\", [ a for a in range(len(df))], True)\n",
        "    # And obv set the indexes for the df\n",
        "    # dfs = dfs.drop_duplicates(subset=['flight', 'step'], keep='last')\n",
        "    # dfs = dfs.set_index([\"flight\", \"step\"])\n",
        "\n",
        "    # Drop the time column!\n",
        "    df = df.drop(\"%time\", axis=1)\n",
        "\n",
        "    # Save it\n",
        "    dfs.append(df)\n",
        "    series_counter+=1\n",
        "\n",
        "print(f\"\\nNumber of Time Series: {len(dfs)}\")\n",
        "assert len(dfs) == 45  # We know the exact number from the repo\n",
        "\n",
        "# Shuffle the array of dataframes for so that classes are not contiguous\n",
        "shuffle(dfs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Remove not usable features"
      ],
      "metadata": {
        "id": "yYKZSxKI3cUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "import numpy as np\n",
        "\n",
        "# Remove useless features and inpute missing values\n",
        "#\n",
        "# finally use the mask on every timeseries of the OG dataframes list\n",
        "\n",
        "# Remove all the features that are not shared by all Time Series\n",
        "#\n",
        "# Only use the variables that can be found in all the dataframes\n",
        "features = []\n",
        "# Get the biggest set:\n",
        "# (We are considering that that the bigger set is just a superset and has all the other base features)\n",
        "for df in dfs:\n",
        "   features = max(features, df.columns.values, key=lambda x: len(x))\n",
        "# Then get the set intersection of all of the features sets\n",
        "features = set(features)\n",
        "for df in dfs:\n",
        "  features = features.intersection(set(df.columns.values))\n",
        "\n",
        "# Apply the feature mask\n",
        "print(len(features))\n",
        "dfs = list(map(lambda x: x[list(features)] , dfs))\n",
        "\n",
        "# Concat all the time series in as single dataframe for later :)\n",
        "concatted_dfs = pd.concat(dfs)\n",
        "concatted_y = concatted_dfs[\"Y\"]\n",
        "concatted_dfs = concatted_dfs.drop(\"Y\", axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0A2_VkK3b_G",
        "outputId": "c3703491-d677-4d8c-a059-30e7ed388fee"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection"
      ],
      "metadata": {
        "id": "TygVNz4Q6jDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### With SelectKBest"
      ],
      "metadata": {
        "id": "hB0vZWpw3FLP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTeZ6pSyXGWC",
        "outputId": "0eb66b58-b5b0-4c57-fe59-1aca40776336"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "field.xtrack_error              57\n",
            "field.aspd_error                57\n",
            "delta_roll_airspeed             60\n",
            "field.linear_acceleration.y    291\n",
            "field.orientation.x            291\n",
            "delta_z                         59\n",
            "delta_yaw                       57\n",
            "field.angular_velocity.y       291\n",
            "field.linear_acceleration.z    291\n",
            "field.twist.angular.y          143\n",
            "delta_pitch                     57\n",
            "field.twist.linear.z           143\n",
            "field.twist.angular.x          143\n",
            "field.alt_error                 57\n",
            "delta_y                         59\n",
            "field.twist.angular.z          143\n",
            "field.linear_acceleration.x    291\n",
            "field.orientation.z            291\n",
            "field.orientation.y            291\n",
            "field.angular_velocity.z       291\n",
            "delta_x                         59\n",
            "field.twist.linear.x           143\n",
            "field.twist.linear.y           143\n",
            "flight                           0\n",
            "delta_roll                      59\n",
            "field.angular_velocity.x       291\n",
            "step                             0\n",
            "dtype: int64\n",
            "Length of Concatted Dataframes: 93670\n"
          ]
        }
      ],
      "source": [
        "# Print the number of nans per per each columns\n",
        "print(concatted_dfs.isnull().sum())\n",
        "print(f\"Length of Concatted Dataframes: {len(concatted_dfs)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "X7tiW05ZEoPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "322d7161-c7c1-4352-e790-551defda414b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Mask:\n",
            "['field.xtrack_error' 'field.aspd_error' 'delta_roll_airspeed'\n",
            " 'field.linear_acceleration.y' 'field.orientation.x' 'delta_z' 'delta_yaw'\n",
            " 'field.linear_acceleration.z' 'delta_pitch' 'field.twist.linear.z'\n",
            " 'field.alt_error' 'delta_y' 'field.linear_acceleration.x'\n",
            " 'field.orientation.z' 'field.orientation.y' 'field.twist.linear.x'\n",
            " 'field.twist.linear.y' 'flight' 'delta_roll' 'step']\n",
            "Length of Feature Mask: 20\n"
          ]
        }
      ],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "import numpy as np\n",
        "\n",
        "# Inpute the nan values to the mean of the other entries value of the same column\n",
        "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imp.fit(concatted_dfs)\n",
        "inp_out = imp.transform(concatted_dfs)\n",
        "\n",
        "# Get the best 20 features of the dataset\n",
        "columns_ = concatted_dfs.columns.values\n",
        "feature_mask= SelectKBest(k=20).fit(inp_out, concatted_y).get_feature_names_out(columns_)\n",
        "\n",
        "# ( Uses sklearn.feature_selection.f_classify )\n",
        "print(\"Feature Mask:\")\n",
        "print(feature_mask)\n",
        "print(f\"Length of Feature Mask: {len(feature_mask)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4SWHHfMYFWn",
        "outputId": "81c40af5-f8da-4ca8-e4f5-cf35ad1f2353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "['field.xtrack_error' 'field.aspd_error' 'delta_roll_airspeed'\n",
            " 'field.linear_acceleration.y' 'field.orientation.x' 'delta_z' 'delta_yaw'\n",
            " 'field.linear_acceleration.z' 'delta_pitch' 'field.twist.linear.z'\n",
            " 'field.alt_error' 'delta_y' 'field.linear_acceleration.x'\n",
            " 'field.orientation.z' 'field.orientation.y' 'field.twist.linear.x'\n",
            " 'field.twist.linear.y' 'flight' 'delta_roll' 'step']\n",
            "[[-3.64743652e+01 -1.58507355e+02  1.50000000e+01  7.84500438e-01\n",
            "  -6.64287492e-02 -5.78435540e-01  1.72930016e+02  1.05013892e+01\n",
            "  -1.18424961e+00 -4.09452055e-01  2.50000000e-01  1.65214367e+01\n",
            "   4.41096354e-02 -4.96952845e-01 -6.12688267e-02  4.41715613e-01\n",
            "   1.69617445e-01  2.00000000e+00  1.86254287e+01  0.00000000e+00]\n",
            " [-3.47822838e+01 -1.49973297e+02  1.50000000e+01  7.84500438e-01\n",
            "  -6.64287492e-02 -5.40839553e-01  1.72930016e+02  1.05013892e+01\n",
            "  -1.14424962e+00 -4.09452055e-01  2.99999982e-01  1.64879150e+01\n",
            "   4.41096354e-02 -4.96952845e-01 -6.12688267e-02  4.41715613e-01\n",
            "   1.69617445e-01  2.00000000e+00  2.05554290e+01  1.00000000e+00]]\n",
            "(2185, 20)\n"
          ]
        }
      ],
      "source": [
        "# apply the features mask and the inputer:\n",
        "#\n",
        "# finally use the mask on every dataframe in the original dataframeList\n",
        "# and also inpute but using time-series specific data:\n",
        "\n",
        "print(type(dfs[0]))\n",
        "print(feature_mask)\n",
        "dfs = list(map(lambda x: SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(x[feature_mask]) , dfs))\n",
        "\n",
        "# Now we have the 20 best features without any nan value:\n",
        "type(dfs[0]) # is a numpy.ndarray! wow!\n",
        "print(dfs[0][:2,:]) # First 2 lines\n",
        "print(dfs[0].shape) # shape of the array"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With randomForest scores:"
      ],
      "metadata": {
        "id": "1pHOsLRJ6twX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP currently it doesn't work\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "concatted_ndarray = SimpleImputer(missing_values=np.nan, strategy='mean').fit_transform(concatted_dfs)\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(concatted_ndarray, concatted_y)\n"
      ],
      "metadata": {
        "id": "LChQqhIZrlrh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f8da3e18-f749-4a9c-f186-161c3f72230a"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_feature_importances(model):\n",
        "    fig_scale = 0.9\n",
        "    n_features = len(concatted_dfs.columns) # take the features names from the Concatted DataFrame\n",
        "    plt.figure(figsize=(7*fig_scale,5.4*fig_scale))\n",
        "    plt.barh(range(n_features), model.feature_importances_, align='center')\n",
        "    plt.yticks(np.arange(n_features), concatted_dfs.columns)\n",
        "    plt.xlabel(\"Feature importance\")\n",
        "    plt.ylabel(\"Feature\")\n",
        "    plt.ylim(-1, n_features)\n",
        "\n",
        "\n",
        "# Plot the feature importances\n",
        "plot_feature_importances(rf)\n",
        "\n",
        "# Select the 10 best features\n",
        "best_features = list(zip(concatted_dfs.columns, rf.feature_importances_))\n",
        "best_features.sort(key=lambda x: x[1])\n",
        "best_features = list(map(lambda x: x[0], best_features[:10]))\n"
      ],
      "metadata": {
        "id": "JEruSVZgoQaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f2LdjIiorMkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split the dataset into windows"
      ],
      "metadata": {
        "id": "tZORfFeIsTJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sktime.split import SlidingWindowSplitter\n",
        "\n",
        "splitted_dfs, window_length, step_length = [], 10, 7\n",
        "splitter = SlidingWindowSplitter(window_length=window_length, step_length=step_length)\n",
        "splitted_dfs = [ splitter.split(df)[0] for df in dfs] # We are ignoring the forecasting horizon\n",
        "splitted_dfs = np.concatenate(splitted_dfs, axis=0 )\n",
        "\n",
        "print(f\"Length of windowed dataset: {len(splitted_dfs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "dFN8Sg2KTYSE",
        "outputId": "1782bb41-4d60-4395-f252-116cb8cf5b0a"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "'generator' object is not subscriptable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-214dd6bcffa2>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msplitted_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlidingWindowSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msplitted_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# We are ignoring the forecasting horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msplitted_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitted_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-214dd6bcffa2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msplitted_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msplitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlidingWindowSplitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwindow_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msplitted_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# We are ignoring the forecasting horizon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msplitted_dfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitted_dfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'generator' object is not subscriptable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature_mask with the n performing best features and then apply the feature_mask to all of our data"
      ],
      "metadata": {
        "id": "k2WreF8jsgdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multi-Indexed Pandas Dataframe (sktime Panel)"
      ],
      "metadata": {
        "id": "N1_zSKdKrybu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0BsGLcFtA_q",
        "outputId": "e39dab9c-0a79-422b-f246-0e3c06e8a29d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(96000, 22)\n",
            "(96000, 20)\n"
          ]
        }
      ],
      "source": [
        "# Deprecated :)\n",
        "#\n",
        "# Finally let's create a multiIndexed pandas.Dataframe so that we can use our data with the sktime library\n",
        "_dfs = []\n",
        "for i, npVals in enumerate(new_dfs):\n",
        "  df = pd.DataFrame(npVals,columns=feature_mask)\n",
        "  df.insert(0, \"flight\", [ i for _ in range(len(df))], True)\n",
        "  df.insert(1, \"step\", [ a for a in range(len(df))], True)\n",
        "  _dfs.append(df)\n",
        "dfs = pd.concat(_dfs)\n",
        "\n",
        "# Set the 2 Indexes (only flight is unique)\n",
        "print(f\"Before: {dfs.shape}\")\n",
        "dfs = dfs.drop_duplicates(subset=['flight', 'step'], keep='last')\n",
        "dfs = dfs.set_index([\"flight\", \"step\"])\n",
        "print(f\"After: {dfs.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-rpr02NwwbN"
      },
      "source": [
        "# Testing Models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nkzUSDs68z6"
      },
      "outputs": [],
      "source": [
        "# list all classifiers in sktime\n",
        "#from sktime.registry import all_estimators\n",
        "#all_estimators(\"classifier\", as_dataframe=True) # , filter_tags={\"capability:unequal_length\":TrueNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fs85Yee5546j"
      },
      "outputs": [],
      "source": [
        "# from sktime.datatypes import MTYPE_REGISTER\n",
        "# pd.DataFrame(MTYPE_REGISTER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kx-Q31Es4qN7"
      },
      "outputs": [],
      "source": [
        "# from sktime.split import temporal_train_test_split\n",
        "# from sktime.datatypes import check_raise\n",
        "#\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sktime.transformations.panel.padder import PaddingTransformer\n",
        "# from sktime.transformations.panel.compose import ColumnConcatenator\n",
        "# from sktime.transformations.panel.interpolate import TSInterpolator\n",
        "#\n",
        "# check_raise(dfs, mtype=\"pd-multiindex\")\n",
        "# check_raise(y_time_series, mtype='np.ndarray')\n",
        "# dfs =  PaddingTransformer().fit_transform(dfs)\n",
        "# y_train, y_test, X_train, X_test  = temporal_train_test_split(X=dfs,y=y_time_series, test_size=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_XtirFiwvvw",
        "outputId": "2e70ca9e-d9a4-4f58-af7a-ce9b339ca973"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sktime/base/_base_panel.py:542: UserWarning: only single label seen in y passed to fit of classifier CNNClassifier\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
        "from sktime.classification.feature_based import RandomIntervalClassifier\n",
        "from sktime.classification.deep_learning.cnn import CNNClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sktime.transformations.panel.padder import PaddingTransformer\n",
        "from sktime.transformations.panel.compose import ColumnConcatenator\n",
        "from sktime.transformations.panel.interpolate import TSInterpolator\n",
        "\n",
        "cnn = CNNClassifier(n_epochs=2000, batch_size=4, kernel_size=3, avg_pool_size=3, n_conv_layers=3, verbose=True, loss='binary_crossentropy')\n",
        "cnn.fit(X_train, y_train)\n",
        "cnn.score(X_test,y_test)\n",
        "\n",
        "#clf = Pipeline([\n",
        "#    (\"transform\", TSInterpolator(50)),\n",
        "#     (\"concatenate\", ColumnConcatenator()),\n",
        "#     (\"classify\", TimeSeriesForestClassifier(n_estimators=100)),\n",
        "#    (\"transform\", PaddingTransformer()),\n",
        "#    (\"classify\", RandomIntervalClassifier(n_intervals=10)),\n",
        "#])\n",
        "#clf.fit(X_train, y_train)\n",
        "#clf.score(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh03M8Wy7ZIN",
        "outputId": "2024558c-1585-479e-867c-d6f06ff0b33e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sktime/base/_base_panel.py:542: UserWarning: only single label seen in y passed to fit of classifier SimpleRNNClassifier\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sktime.classification.deep_learning.rnn import SimpleRNNClassifier\n",
        "from sklearn.model_selection import LearningCurveDisplay\n",
        "\n",
        "rnn = SimpleRNNClassifier(n_epochs=20, batch_size=20)\n",
        "rnn.fit(X_train, y_train)\n",
        "rnn.score(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}